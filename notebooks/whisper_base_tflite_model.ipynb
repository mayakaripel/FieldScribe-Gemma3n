{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install required tools"
      ],
      "metadata": {
        "id": "qeVMElVTkeVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing whisper package\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "#Insalloing datasets\n",
        "!pip install datasets\n",
        "\n",
        "# Cloning whisper repository\n",
        "!git clone https://github.com/openai/whisper.git\n",
        "\n",
        "# Downloading a sample audio file\n",
        "!wget https://huggingface.co/datasets/osanseviero/dummy_ja_audio/resolve/main/result.flac"
      ],
      "metadata": {
        "id": "lmSS-RSdjXhp",
        "outputId": "a928f07e-6c4b-4b76-847d-fdf1fc42dcb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-oqv_hgcp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-oqv_hgcp\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper==20250625) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=8c46d6f0aa183a3dccab28429179a710f4dfe904d82bb41ebfa7c5cff00225ca\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vxxuttad/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Cloning into 'whisper'...\n",
            "remote: Enumerating objects: 886, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 886 (delta 7), reused 6 (delta 6), pack-reused 870 (from 3)\u001b[K\n",
            "Receiving objects: 100% (886/886), 12.50 MiB | 19.57 MiB/s, done.\n",
            "Resolving deltas: 100% (506/506), done.\n",
            "--2025-09-23 03:37:08--  https://huggingface.co/datasets/osanseviero/dummy_ja_audio/resolve/main/result.flac\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.65, 3.166.152.105, 3.166.152.110, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/63403655388c3fa40f9847f9/9bd079c132b36ffe9cfcf392785009df68b13550da3f6000f3504ceb62da223c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250923T033708Z&X-Amz-Expires=3600&X-Amz-Signature=e30b811ba0572bcb5f192d3faf3cde1484e250c1d18f192a184e3e153cfac67b&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27result.flac%3B+filename%3D%22result.flac%22%3B&response-content-type=audio%2Fx-flac&x-id=GetObject&Expires=1758602228&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODYwMjIyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MzQwMzY1NTM4OGMzZmE0MGY5ODQ3ZjkvOWJkMDc5YzEzMmIzNmZmZTljZmNmMzkyNzg1MDA5ZGY2OGIxMzU1MGRhM2Y2MDAwZjM1MDRjZWI2MmRhMjIzYyoifV19&Signature=CtgQRy8GnJuSdOMOGIY1DNvnefJd1MbB4QoraheFdbw9jESYwXbBKwPub8e1bzfgxI-WCBD-qfcRtmZXMpMe9EPeWOcw6Lvie1QuhO9hEib6n7V1hfd%7Edg7XYB74xg0YfqB5fToJTx-CkRDn-ToRfqujQAjfz0uqM9W0aX8LN5eP%7ExTJ9hx4kU%7E0ZHw1ePlhYOJbWFEIbv5Xq0JjwO6yHuBZ14yMcFtDVkl3NdRRq2TP5GOz%7EbkxvkBJDo%7EuW4SYhJQOs12XytGzlkZSUyAlsgq96yhcHVN7S043toMX5JdTt7yKD0dTi3HccbGqs6fEAeetTpc7Flwb%7EDrVYE3IZQ__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-23 03:37:08--  https://cas-bridge.xethub.hf.co/xet-bridge-us/63403655388c3fa40f9847f9/9bd079c132b36ffe9cfcf392785009df68b13550da3f6000f3504ceb62da223c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250923T033708Z&X-Amz-Expires=3600&X-Amz-Signature=e30b811ba0572bcb5f192d3faf3cde1484e250c1d18f192a184e3e153cfac67b&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27result.flac%3B+filename%3D%22result.flac%22%3B&response-content-type=audio%2Fx-flac&x-id=GetObject&Expires=1758602228&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODYwMjIyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MzQwMzY1NTM4OGMzZmE0MGY5ODQ3ZjkvOWJkMDc5YzEzMmIzNmZmZTljZmNmMzkyNzg1MDA5ZGY2OGIxMzU1MGRhM2Y2MDAwZjM1MDRjZWI2MmRhMjIzYyoifV19&Signature=CtgQRy8GnJuSdOMOGIY1DNvnefJd1MbB4QoraheFdbw9jESYwXbBKwPub8e1bzfgxI-WCBD-qfcRtmZXMpMe9EPeWOcw6Lvie1QuhO9hEib6n7V1hfd%7Edg7XYB74xg0YfqB5fToJTx-CkRDn-ToRfqujQAjfz0uqM9W0aX8LN5eP%7ExTJ9hx4kU%7E0ZHw1ePlhYOJbWFEIbv5Xq0JjwO6yHuBZ14yMcFtDVkl3NdRRq2TP5GOz%7EbkxvkBJDo%7EuW4SYhJQOs12XytGzlkZSUyAlsgq96yhcHVN7S043toMX5JdTt7yKD0dTi3HccbGqs6fEAeetTpc7Flwb%7EDrVYE3IZQ__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.173.166.5, 18.173.166.82, 18.173.166.74, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.173.166.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70166 (69K) [audio/x-flac]\n",
            "Saving to: ‘result.flac’\n",
            "\n",
            "result.flac         100%[===================>]  68.52K   415KB/s    in 0.2s    \n",
            "\n",
            "2025-09-23 03:37:08 (415 KB/s) - ‘result.flac’ saved [70166/70166]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Whisper TFLite model"
      ],
      "metadata": {
        "id": "iGP8xDa3knH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb9TvLmehMQa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Importing necessary classes from transformers\n",
        "from transformers import AutoProcessor, TFWhisperForConditionalGeneration, GenerationConfig\n",
        "\n",
        "# Importing necessary functions from datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# Creating force_token_map to be used in GenerationConfig\n",
        "force_token_map = [[50258, 50266], [50359, 50363]] #\n",
        "\n",
        "# Creating generation_config with force_token_map\n",
        "generation_config = GenerationConfig(force_token_map=force_token_map)\n",
        "\n",
        "# Creating an instance of AutoProcessor from the pretrained model\n",
        "processor = AutoProcessor.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "# Creating an instance of TFWhisperForConditionalGeneration from the pretrained model\n",
        "model = TFWhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "# Loading dataset\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "\n",
        "# Inputs\n",
        "inputs = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"tf\")\n",
        "input_features = inputs.input_features\n",
        "\n",
        "# Generating Transcription\n",
        "generated_ids = model.generate(input_ids=input_features, generation_config=generation_config)\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(transcription)\n",
        "\n",
        "# Creating a GenerateModel Class\n",
        "class GenerateModel(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    super(GenerateModel, self).__init__()\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "    input_signature=[\n",
        "      tf.TensorSpec(shape=(1, 80,3000), dtype=tf.float32, name=\"input_ids\"),\n",
        "    ]\n",
        "  )\n",
        "  def serving(self, input_ids):\n",
        "    outputs = self.model.generate(input_ids, forced_decoder_ids=force_token_map)\n",
        "    return {\"sequences\": outputs}\n",
        "\n",
        "# Saving the model\n",
        "saved_model_dir = '/content/tf'\n",
        "generate_model = GenerateModel(model=model)\n",
        "tf.saved_model.save(generate_model, saved_model_dir, signatures={\"serving_default\": generate_model.serving})\n",
        "\n",
        "# Converting to TFLite model\n",
        "tflite_model_path = '/content/whisper-base.tflite'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Saving the TFLite model\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run the inference on Whisper TFLite model"
      ],
      "metadata": {
        "id": "N2b4VZBqkpT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import whisper\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "\n",
        "# Define the path to the TFLite model\n",
        "tflite_model_path = '/content/whisper-base.tflite'\n",
        "\n",
        "# Create an interpreter to run the TFLite model\n",
        "interpreter = tf.lite.Interpreter(tflite_model_path)\n",
        "\n",
        "# Allocate memory for the interpreter\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get the input and output tensors\n",
        "input_tensor = interpreter.get_input_details()[0]['index']\n",
        "output_tensor = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "\n",
        "inference_start = timer()\n",
        "\n",
        "# Calculate the mel spectrogram of the audio file\n",
        "print(f'Calculating mel spectrogram...')\n",
        "mel_from_file = whisper.audio.log_mel_spectrogram('/content/whisper/tests/jfk.flac')\n",
        "\n",
        "# Pad or trim the input data to match the expected input size\n",
        "input_data = whisper.audio.pad_or_trim(mel_from_file, whisper.audio.N_FRAMES)\n",
        "\n",
        "# Add a batch dimension to the input data\n",
        "input_data = np.expand_dims(input_data, 0)\n",
        "\n",
        "# Run the TFLite model using the interpreter\n",
        "print(\"Invoking interpreter ...\")\n",
        "interpreter.set_tensor(input_tensor, input_data)\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output data from the interpreter\n",
        "output_data = interpreter.get_tensor(output_tensor)\n",
        "\n",
        "# Print the output data\n",
        "#print(output_data)\n",
        "\n",
        "# Create a tokenizer to convert tokens to text\n",
        "wtokenizer = whisper.tokenizer.get_tokenizer(True, language=\"ja\")\n",
        "\n",
        "# convert tokens to text\n",
        "print(\"Converting tokens ...\")\n",
        "for token in output_data:\n",
        "    # Replace -100 with the end of text token\n",
        "    token[token == -100] = wtokenizer.eot\n",
        "    text = wtokenizer.decode(token, skip_special_tokens=True)\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nInference took {:.2f}s \".format(timer() - inference_start))"
      ],
      "metadata": {
        "id": "TzCrY9Q5jVsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -la"
      ],
      "metadata": {
        "id": "3cZE5TG5loVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}